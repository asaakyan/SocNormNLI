{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 22:58:51.811491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 22:58:53.764703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2023-01-20 22:58:53.764797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2023-01-20 22:58:53.764804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device0 = torch.device(\"cuda:0\")\n",
    "device1 = torch.device(\"cuda:1\")\n",
    "device2 = torch.device(\"cuda:2\")\n",
    "device3 = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM\n",
    "    )\n",
    "\n",
    "def load_model(model_path, device):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, cache_dir=\"./huggingface_models\")\n",
    "    if 'xxl' in model_path:\n",
    "        print('working w flan-xxl')\n",
    "        model.parallelize()\n",
    "    else:\n",
    "        model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transl(prompt, model, tokenizer, device):\n",
    "\n",
    "    if not device:\n",
    "        features = tokenizer(prompt, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    else:\n",
    "        features = tokenizer(prompt, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # https://huggingface.co/blog/how-to-generate\n",
    "        generated_ids = model.generate(\n",
    "            **features,\n",
    "            no_repeat_ngram_size=2, \n",
    "            min_length=10, \n",
    "            do_sample=True,\n",
    "            max_length=128,\n",
    "            top_k=5, \n",
    "            temperature=0.7,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"It's bad to hate your mom.\",\n",
       " 'It is not necessary to be filial to your mother to a great extent.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_us_and_zh_norm(en1):\n",
    "    us = en1[en1.index('\\\"')+1:en1.index('\\\" entail,')]\n",
    "    skip = 'to the sentence \\\"'\n",
    "    zh = en1[en1.index(skip)+len(skip):en1.index('\\\"? Please')]\n",
    "    return us, zh\n",
    "\n",
    "en1 = \"Does the sentence \\\"It's bad to hate your mom.\\\" entail, contradict, or has no relation to the sentence \\\"It is not necessary to be filial to your mother to a great extent.\\\"? Please answer between \\\"Entailment\\\", \\\"Contradiction\\\" or \\\"No Relation\\\" and explain your decision.\"\n",
    "extract_us_and_zh_norm(en1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Contradiction',\n",
       " 'The Chinese and US cultures are different when it comes to family and child-rearing and so the US norm would be based on the idea of respect and honoring the mother and father while the Chinese norm is centered on personal choice and family planning')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/socnli_t5/socNLI_val.json', 'r') as f:\n",
    "        val = json.load(f)\n",
    "        \n",
    "def get_fs_prompt_for_dream(val, n=10):\n",
    "    few_shot_prompt = \"\"\n",
    "    for i, row in enumerate(val[:n]):\n",
    "        \n",
    "        us, zh = extract_us_and_zh_norm(row['translation']['en1'])\n",
    "        p_q = f\"Premise: [Premise - social norm] {us} Hypothesis: [Hypothesis - social norm] {zh} Is there a contradiction, entailment, or no relation between the premise and hypothesis?\"\n",
    "        gold = row['translation']['en2']\n",
    "        ans, expl = gold.split(\".\")[0], gold.split('.')[1].strip()\n",
    "        p_ans = f\"Answer : {ans}. Explanation : {expl}\"\n",
    "        v = f\"{p_q}\\n{p_ans}\"\n",
    "        if i == 0:\n",
    "            few_shot_prompt = v\n",
    "        else:\n",
    "            few_shot_prompt += f\"\\n\\n{v}\"\n",
    "    return few_shot_prompt\n",
    "\n",
    "def extract_resp_from_dream(ans):\n",
    "    lab = ans[ans.index(': ')+2:ans.index('. Expl')].strip()\n",
    "    skip = \"Explanation\"\n",
    "    expl = ans[ans.index(skip)+len(skip)+2:].strip().replace('- ', '')\n",
    "    return lab, expl\n",
    "\n",
    "ans = \"  Answer : Contradiction. Explanation ; The Chinese and US cultures are different when it comes to family and child-rearing and so the US norm would be based on the idea of respect and honoring the mother and father while the Chinese norm is centered on personal choice and family planning\"\n",
    "extract_resp_from_dream(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def eval_model(model, tokenizer, device, model_name,\n",
    "                verbose=False, debug=False,\n",
    "                test_path = \"./data/socnli_t5/socNLI_test.json\"):\n",
    "    \n",
    "    if \"t5_IO\" not in test_path and \"t5_IR\" not in test_path:\n",
    "        with open(test_path, \"r\") as f:\n",
    "            test_data = json.load(f)\n",
    "    else:\n",
    "        with open(test_path, \"r\") as f:\n",
    "            test_data = [json.loads(l) for l in f.readlines()]\n",
    "\n",
    "    with open('./data/socnli_t5/socNLI_val.json', 'r') as f:\n",
    "        val = json.load(f)\n",
    "\n",
    "    if model_name=='dream':\n",
    "        prompt = get_fs_prompt_for_dream(val, n=10)\n",
    "    elif model_name in {'t5-flan', 't5-flan-xxl'}:\n",
    "        prompt = \"\\n\\n\".join([r['translation']['en1']\n",
    "                                        +\"\\n\"\n",
    "                                        +r['translation']['en2'] \n",
    "                                        for r in val[:10]])\n",
    "    else:\n",
    "        prompt = \"\"\n",
    "\n",
    "    preds = []\n",
    "    for i, t in tqdm(enumerate(test_data)):\n",
    "\n",
    "        tr = t['translation']\n",
    "        ### if flan want to provide a few-shot prompt\n",
    "        if model_name in {'t5-flan', 't5-flan-xxl'}:\n",
    "            input = f\"{prompt}\\n\\n{tr['en1']}\".replace('No Relation', 'Neutral')\n",
    "            # input = f\"{tr['en1']}\"\n",
    "            resp = generate_transl(input, model, tokenizer, device).replace('..', '.')\n",
    "            resp = resp.replace('Neutral', 'No Relation')\n",
    "        elif model_name=='dream':\n",
    "            us, zh = extract_us_and_zh_norm(tr['en1'])\n",
    "            if debug:\n",
    "                print(us)\n",
    "                print(zh)\n",
    "            input = f\"{prompt}\\n\\nPremise: [Premise - social norm] {us}. Hypothesis: [Hypothesis - social norm] {zh}. Is there a contradiction, entailment, or no relation between the premise and hypothesis?\"\n",
    "            #input = f\"Premise: [Premise - social norm] {us}. Hypothesis: [Hypothesis - social norm] {zh}. Is there a contradiction, entailment, or no relation between the premise and hypothesis?\"\n",
    "            resp = generate_transl(prompt, model, tokenizer, device)\n",
    "        else:\n",
    "            resp = generate_transl(tr['en1'], model, tokenizer, device)\n",
    "        \n",
    "        if debug: \n",
    "            print(\"RESPONSE: \", resp)\n",
    "\n",
    "        if model_name == 'dream':\n",
    "            y_pred, expl_pred = extract_resp_from_dream(resp)\n",
    "            y_true, expl_true = tr['en2'].split('.')[0], tr['en2'].split('.')[1].strip()\n",
    "            if debug:\n",
    "                print(y_pred)\n",
    "                print(expl_pred)\n",
    "                print('*')\n",
    "        elif model_name == 't5-io':\n",
    "            if 'Entailment' in resp:\n",
    "                y_pred = 'Entailment'\n",
    "            elif 'Contradiction' in resp:\n",
    "                 y_pred = 'Contradiction'\n",
    "            else:\n",
    "                y_pred = 'No Relation'\n",
    "            y_true =  tr['en2']\n",
    "            expl_pred, expl_true = None, None\n",
    "        elif model_name == 't5-ir_o':\n",
    "            if 'Entailment' in resp:\n",
    "                y_pred = 'Entailment'\n",
    "            elif 'Contradiction' in resp:\n",
    "                 y_pred = 'Contradiction'\n",
    "            else:\n",
    "                y_pred = 'No Relation'\n",
    "            y_true =  tr['en2']\n",
    "            expl_pred, expl_true = None, None\n",
    "        else:\n",
    "            if 'Entailment.' not in resp \\\n",
    "                and 'Contradiction.' not in resp \\\n",
    "                    and 'No Relation.' not in resp:\n",
    "                y_true, y_pred = tr['en2'].split('.')[0], 'fail'\n",
    "                expl_true, expl_pred = tr['en2'].split('.')[1].strip(), 'fail'\n",
    "            else:\n",
    "                y_true, y_pred = tr['en2'].split('.')[0], resp.split('.')[0]\n",
    "                expl_true, expl_pred = tr['en2'].split('.')[1].strip(), resp.split('.')[1].strip()\n",
    "        if verbose:\n",
    "            # print(tr['en1'])\n",
    "            # print(tr['en2'])\n",
    "            # print(resp)\n",
    "            print(y_true, y_pred)\n",
    "            # print(expl_true)\n",
    "            # print(expl_pred)\n",
    "        preds.append([i, y_true, y_pred, expl_true, expl_pred])\n",
    "        if debug and i>10:\n",
    "            break\n",
    "\n",
    "    preds_df = pd.DataFrame(preds, columns=['ID', 'y_true', 'y_pred', 'expl_true', 'expl_pred'])\n",
    "    preds_df.to_csv(f'./data/model_outputs_test_set/{model_name}.csv', index=False)\n",
    "\n",
    "    return preds_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SocNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "768it [09:34,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# socnli_path = \"/local/nlpswordfish/a.saakyan/socnorms/t5-socnli-batch2/checkpoint-140\"\n",
    "# soc_model, soc_tok = load_model(socnli_path, device1)\n",
    "#pdf_socnorm = eval_model(soc_model, soc_tok, device1, 't5-socnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5452316190056435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score(pdf_socnorm['y_true'], pdf_socnorm['y_pred'], average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esnli_path = \"/home/a.saakyan/models/t5-esnli-batch2/checkpoint-268\"\n",
    "# esnli_model, esnli_tok = load_model(esnli_path, device0)\n",
    "# pdf_esnli= eval_model(esnli_model, esnli_tok, device0, 't5-esnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.334823198909099"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score(pdf_esnli['y_true'], pdf_esnli['y_pred'], average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flan_path = \"google/flan-t5-xl\"\n",
    "# flan_model, flan_tok = load_model(flan_path, device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "768it [07:12,  1.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07217330409986283"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdf_flan= eval_model(flan_model, flan_tok, device0, 't5-flan')\n",
    "# f1_score(pdf_flan['y_true'], pdf_flan['y_pred'], average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dream_model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System3_DREAM_FLUTE_social_norm_FigLang2022\",\n",
    "# cache_dir=\"./huggingface_models\").to(device2)\n",
    "# dream_tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "768it [12:04,  1.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17675943278990255"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_dream= eval_model(dream_model, dream_tokenizer, device2, 'dream')\n",
    "f1_score(pdf_dream['y_true'], pdf_dream['y_pred'], average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I->OR vs I->O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_path = \"./t5-socnli-io/checkpoint-70/\"\n",
    "io_model, io_tok = load_model(io_path, device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "768it [03:14,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "pdf_io = eval_model(io_model, io_tok, device0, 't5-io', \n",
    "test_path=\"./data/socnli_t5_IO/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5338541666666666\n",
      "0.4973825601778697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(accuracy_score(pdf_io['y_true'], pdf_io['y_pred']))\n",
    "print(f1_score(pdf_io['y_true'], pdf_io['y_pred'], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "768it [03:18,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "ir_o_path = \"./t5-socnli-ir_o/checkpoint-70/\"\n",
    "ir_o_model, ir_o_tok = load_model(ir_o_path, device1)\n",
    "pdf_ir_o = eval_model(ir_o_model, ir_o_tok, device1, 't5-ir_o', test_path=\"./data/socnli_t5_IR_O/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>expl_true</th>\n",
       "      <th>expl_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>763</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>764</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>765</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>766</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>No Relation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>767</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID         y_true         y_pred expl_true expl_pred\n",
       "0      0    No Relation    No Relation      None      None\n",
       "1      1     Entailment     Entailment      None      None\n",
       "2      2     Entailment  Contradiction      None      None\n",
       "3      3  Contradiction  Contradiction      None      None\n",
       "4      4    No Relation    No Relation      None      None\n",
       "..   ...            ...            ...       ...       ...\n",
       "763  763    No Relation    No Relation      None      None\n",
       "764  764     Entailment     Entailment      None      None\n",
       "765  765    No Relation    No Relation      None      None\n",
       "766  766    No Relation    No Relation      None      None\n",
       "767  767     Entailment     Entailment      None      None\n",
       "\n",
       "[768 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_ir_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609375\n",
      "0.9474649172241077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(accuracy_score(pdf_ir_o['y_true'], pdf_ir_o['y_pred']))\n",
    "print(f1_score(pdf_ir_o['y_true'], pdf_ir_o['y_pred'], average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364d9abb7aff696efb13be5ca97d520191fd5077dc6f659faeff954c3f4fe3ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
